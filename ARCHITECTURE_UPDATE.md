# æ¶æ„æ›´æ–°è¯´æ˜ - Latent Diffusion å®ç°

## ğŸ¯ æ ¸å¿ƒæ”¹è¿›

æœ¬æ¬¡æ›´æ–°å°†æ‰©æ•£æ¨¡å‹ä»**æŠ½è±¡å‘é‡ç©ºé—´**è¿ç§»åˆ°**å›¾åƒlatentç©ºé—´**ï¼Œå¹¶é‡‡ç”¨**éå¯¹ç§°å¼è·¨æ¨¡æ€ç”Ÿæˆç­–ç•¥**ã€‚

---

## ğŸ“‹ ä¸»è¦å˜æ›´

### 1. æ–°å¢æ–‡ä»¶

#### `latent_diffusion.py`
å®Œæ•´çš„Latent Diffusionå®ç°ï¼ŒåŒ…å«ï¼š
- **LatentDiffusionUNet**: ä¸»æ‰©æ•£æ¨¡å‹ç±»ï¼ˆDDIMé‡‡æ ·ï¼‰
- **ConditionalUNet2D**: UNetå»å™ªç½‘ç»œï¼ˆå¤„ç†2D spatial structureï¼‰
- **ResBlockWithCondition**: å¸¦FiLMæ¡ä»¶æ³¨å…¥çš„æ®‹å·®å—
- **AttentionBlock**: å¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—
- **SinusoidalPositionEmbedding**: æ—¶é—´æ­¥ç¼–ç 

**å…³é”®ç‰¹æ€§**ï¼š
- åœ¨256Ã—7Ã—7 latent spaceæ“ä½œï¼ˆä¸æ˜¯512ç»´å‘é‡ï¼‰
- UNetæ¶æ„ä¿ç•™spatial structure
- Text embeddingé€šè¿‡FiLMæ³¨å…¥åˆ°æ¯ä¸ªResBlock
- DDIMé‡‡æ ·åŠ é€Ÿæ¨ç†ï¼ˆ10-100æ­¥ï¼‰

---

### 2. main.py ä¿®æ”¹

#### ImageDecoder ç±»å¢å¼º
```python
# æ–°å¢æ–¹æ³•ï¼š
def decode_from_latent(self, latents):
    """ä»æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„latentç›´æ¥è§£ç å›¾åƒ"""

def get_latent_from_embedding(self, embeddings):
    """å°†embeddingè½¬æ¢ä¸ºlatentï¼ˆè®­ç»ƒæ—¶ä½¿ç”¨ï¼‰"""
```

#### GenerativeMultimodalModel é‡å¤§æ›´æ–°

**æ—§è®¾è®¡ âŒ**ï¼š
```python
self.diffusion = DiffusionModel(embed_dim, ...)  # MLPåœ¨512ç»´å‘é‡ä¸Š
```

**æ–°è®¾è®¡ âœ…**ï¼š
```python
self.latent_diffusion = LatentDiffusionUNet(
    latent_channels=256,  # åŒ¹é…ImageDecoder latent
    latent_size=7,        # 2D spatial size
    condition_dim=512,    # Text embeddingç»´åº¦
    num_timesteps=1000
)
```

**æ–°å¢/ä¿®æ”¹çš„æ–¹æ³•**ï¼š

1. **compute_diffusion_loss(image_features, text_features)**
   - è®­ç»ƒç›®æ ‡ï¼š`text_embedding â†’ denoise â†’ image_latent`
   - æ¡ä»¶æ‰©æ•£è®­ç»ƒï¼ˆtextä½œä¸ºconditionï¼‰

2. **generate_image_from_text(text_embeddings, num_inference_steps=50)**
   - Text â†’ Image æ¨ç†æ¥å£
   - ä½¿ç”¨Latent Diffusionç”Ÿæˆé«˜è´¨é‡å›¾åƒ

3. **generate_text_from_image(image_embeddings)**
   - Image â†’ Text æ¨ç†æ¥å£
   - Autoregressive Transformerç”Ÿæˆ

4. ~~**cross_modal_generation**~~
   - å·²å¼ƒç”¨ï¼ˆæœ‰bugï¼šç¼ºå°‘attention_maskï¼‰
   - è¯·ä½¿ç”¨ä¸Šè¿°ä¸¤ä¸ªæ–°æ–¹æ³•

---

### 3. test.py æ›´æ–°

**ä¸»è¦æ”¹åŠ¨**ï¼šä½¿ç”¨æ–°çš„ `generate_image_from_text` æ–¹æ³•

```python
# æ—§ä»£ç  âŒ
generated_embedding = self.model.diffusion.sample(
    condition=text_embedding,  # è®­ç»ƒæ—¶ä»æœªè§è¿‡è¿™ç§ç”¨æ³•ï¼
    ...
)

# æ–°ä»£ç  âœ…
generated_image = self.model.generate_image_from_text(
    text_embedding,
    num_inference_steps=50  # æ¨è30-50æ­¥
)
```

**æ¨èå‚æ•°**ï¼š
- `use_diffusion=True` ï¼ˆé»˜è®¤ï¼Œé«˜è´¨é‡ï¼‰
- `num_inference_steps=30-50` ï¼ˆå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦ï¼‰

---

### 4. test02.py æ›´æ–°

**ä¸»è¦æ”¹åŠ¨**ï¼šç§»é™¤ä¸å¿…è¦çš„ `use_diffusion` å‚æ•°

```python
# Image â†’ Text ä¸éœ€è¦æ‰©æ•£ï¼
results = generator.generate_from_image(
    image_paths,
    num_captions_per_image=3,
    temperature=0.9,  # åªéœ€è°ƒæ•´è§£ç å‚æ•°
    top_k=50
)
```

**ç†ç”±**ï¼š
- æ–‡æœ¬æ˜¯ç¦»æ•£tokenåºåˆ—ï¼ŒTransformer autoregressiveå·²ç»è¶³å¤Ÿå¥½
- æ‰©æ•£æ¨¡å‹æ˜¯ä¸ºè¿ç»­æ•°æ®ï¼ˆå›¾åƒï¼‰è®¾è®¡çš„

---

## ğŸ—ï¸ æ–°æ¶æ„è®¾è®¡ç†å¿µ

### éå¯¹ç§°å¼è·¨æ¨¡æ€ç”Ÿæˆ

```
Direction 1: Image â†’ Text (Autoregressive)
  Image â†’ ImageEncoder â†’ [512-d] â†’ TextDecoder â†’ Text
  âœ“ Transformeræ“…é•¿åºåˆ—ç”Ÿæˆ

Direction 2: Text â†’ Image (Diffusion)
  Text â†’ TextEncoder â†’ [512-d] â†’ LatentDiffusion â†’ [256Ã—7Ã—7] â†’ ImageDecoder â†’ Image
  âœ“ æ‰©æ•£æ¨¡å‹æ“…é•¿ç”Ÿæˆç»“æ„åŒ–å›¾åƒ
```

### ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

| æ–¹å‘ | æ•°æ®ç‰¹æ€§ | æ¨¡å‹é€‰æ‹© | ç†ç”± |
|------|----------|---------|------|
| **Imageâ†’Text** | ç¦»æ•£åºåˆ— | Autoregressive Transformer | GPT/BERTå·²è¯æ˜SOTA |
| **Textâ†’Image** | è¿ç»­2Dåƒç´  | Latent Diffusion UNet | Stable Diffusion / DALL-E 2 è¯æ˜SOTA |

**å…³é”®æ´å¯Ÿ**ï¼šä¸åŒæ¨¡æ€åº”è¯¥ç”¨ä¸åŒçš„ç”Ÿæˆç­–ç•¥ï¼Œè€Œä¸æ˜¯å¼ºè¡Œå¯¹ç§°ï¼

---

## ğŸ› ä¿®å¤çš„Bug

### Bug 1: cross_modal_generation ç¼ºå°‘å‚æ•°
```python
# æ—§ä»£ç ï¼ˆBugï¼‰
embeddings = self.text_encoder(source)  # âŒ ç¼ºå°‘attention_mask

# åº”è¯¥æ˜¯
embeddings = self.text_encoder(input_ids, attention_mask)  # âœ“
```

### Bug 2: æ‰©æ•£æ¨¡å‹è®­ç»ƒ-æ¨ç†ä¸ä¸€è‡´
```python
# è®­ç»ƒæ—¶ï¼šæ— æ¡ä»¶æ‰©æ•£
predicted_noise = self.diffusion.predict_noise(noisy_embeddings, t)  # âŒ æ²¡ä¼ condition

# æ¨ç†æ—¶ï¼šå´å½“æœ‰æ¡ä»¶ç”¨
generated = self.diffusion.sample(condition=text_embedding)  # âŒ è®­ç»ƒæ²¡è§è¿‡è¿™ä¸ªä»»åŠ¡
```

### Bug 3: æ¡ä»¶ä¿¡æ¯æœªè¿›å…¥ç½‘ç»œ
```python
# æ—§å®ç°
x_in = torch.cat([x_t, t_emb], dim=-1)  # âŒ æ²¡æœ‰concat condition
if condition is not None:
    noise_pred = noise_pred - guidance_scale * (condition - x_t)  # ç®€å•å‘é‡å‡æ³•ï¼Œä¸æ˜¯çœŸæ­£çš„æ¡ä»¶æ‰©æ•£

# æ–°å®ç°
cond = t_emb + c_emb  # âœ“ åˆå¹¶timeå’Œcondition
h = h * (1 + scale) + shift  # âœ“ FiLMæ³¨å…¥åˆ°æ¯ä¸ªResBlock
```

---

## ğŸ“Š æ¶æ„å¯¹æ¯”

| æ–¹é¢ | æ—§è®¾è®¡ âŒ | æ–°è®¾è®¡ âœ“ |
|------|----------|----------|
| **æ‰©æ•£ç©ºé—´** | 512ç»´æŠ½è±¡å‘é‡ | 256Ã—7Ã—7 latent (2D) |
| **ç½‘ç»œç»“æ„** | MLP | UNet (CNN+Attention) |
| **æ¡ä»¶æ³¨å…¥** | åæœŸå‘é‡å‡æ³• | FiLMæ³¨å…¥æ¯å±‚ |
| **è®­ç»ƒç›®æ ‡** | æ— æ¡ä»¶å»å™ª | Textâ†’Imageæ¡ä»¶å»å™ª |
| **Spatial Prior** | âœ— | âœ“ ä¿ç•™2Dç»“æ„ |
| **è®­ç»ƒ-æ¨ç†ä¸€è‡´** | âœ— | âœ“ |

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### è®­ç»ƒï¼ˆæ— éœ€ä¿®æ”¹ï¼‰

è®­ç»ƒä»£ç è‡ªåŠ¨ä½¿ç”¨æ–°çš„Latent Diffusionï¼š

```bash
python main.py
```

è®­ç»ƒæ—¶ä¼šï¼š
1. å¯¹é½embeddingç©ºé—´ï¼ˆcontrastive lossï¼‰
2. è®­ç»ƒdecoderï¼ˆreconstruction lossï¼‰
3. **è®­ç»ƒLatent Diffusion**ï¼ˆtext â†’ image_latent å»å™ªï¼‰

### æ¨ç†ï¼šText â†’ Image

```python
python test.py
```

```python
# åœ¨test.pyä¸­
results = generator.generate_from_text(
    prompts=["a dog playing in the park", "a beautiful sunset"],
    num_samples_per_prompt=2,
    use_diffusion=True,        # æ¨èTrueï¼ˆé«˜è´¨é‡ï¼‰
    num_inference_steps=50,    # 30-50æ­¥å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
    seed=42                    # å¯é€‰ï¼Œç”¨äºå¤ç°
)
```

**å‚æ•°è°ƒä¼˜**ï¼š
- `num_inference_steps=10-20`: å¿«é€Ÿé¢„è§ˆ
- `num_inference_steps=30-50`: æ¨èï¼ˆè´¨é‡å¥½ï¼‰
- `num_inference_steps=50-100`: æœ€ä½³è´¨é‡ï¼ˆæ…¢ï¼‰

### æ¨ç†ï¼šImage â†’ Text

```python
python test02.py
```

```python
# åœ¨test02.pyä¸­
results = generator.generate_from_image(
    image_paths=["path/to/image.jpg"],
    num_captions_per_image=3,
    temperature=0.9,           # 0.7-0.8æ›´focusedï¼Œ0.9-1.0æ›´diverse
    top_k=50,
    top_p=0.9,
    repetition_penalty=1.3
)
```

---

## âš ï¸ é‡è¦æç¤º

### 1. å…¼å®¹æ€§
- **éœ€è¦é‡æ–°è®­ç»ƒ**ï¼šæ—§æ¨¡å‹checkpointä¸å…¼å®¹
- æ¨¡å‹ç»“æ„å˜åŒ–ï¼šdiffusion â†’ latent_diffusion

### 2. ä¾èµ–æ£€æŸ¥
```bash
# ç¡®ä¿æœ‰ä»¥ä¸‹åŒ…
pip install torch torchvision transformers pillow pandas tqdm
```

### 3. GPUå†…å­˜
- Latent Diffusionæ¯”åƒç´ ç©ºé—´æ‰©æ•£çœ100å€å†…å­˜
- UNetå‚æ•°é‡é€‚ä¸­ï¼ˆçº¦50Må‚æ•°ï¼‰
- æ¨ç†æ—¶batch_size=1-4è¶³å¤Ÿ

### 4. é¦–æ¬¡è¿è¡Œ
```bash
# é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½BERTæ¨¡å‹ï¼ˆçº¦400MBï¼‰
# ä¼šç¼“å­˜åˆ° ./models/bert_cache/
```

---

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### Latent Space è®¾è®¡

```
Embedding (512-d vector)
    â†“ [ImageDecoder.projection]
Latent (256 channels, 7Ã—7 spatial)  â† æ‰©æ•£åœ¨è¿™é‡Œæ“ä½œ
    â†“ [ImageDecoder.decoder]
Image (3 channels, 224Ã—224 pixels)
```

**ä¸ºä»€ä¹ˆæ˜¯7Ã—7ï¼Ÿ**
- ImageEncoderä»224Ã—224é™åˆ°7Ã—7ï¼ˆç»è¿‡5å±‚stride=2å·ç§¯ï¼‰
- ä¿ç•™spatial structureçš„æœ€å°å°ºå¯¸
- æ¯”åƒç´ ç©ºé—´å¿«1000å€ï¼ˆ224Â²/7Â² â‰ˆ 1024å€ï¼‰

### UNet ç»“æ„

```
Input: (B, 256, 7, 7) + Text Embedding (B, 512)
    â†“
[Initial Conv] â†’ (B, 128, 7, 7)
    â†“
[Encoder]
  ResBlock + FiLM(time+text) â†’ (B, 256, 7, 7) â”€â”
  ResBlock + FiLM(time+text) â†’ (B, 512, 7, 7) â”€â”¤
    â†“                                           â”‚
[Middle]                                        â”‚
  ResBlock + Attention â†’ (B, 512, 7, 7)         â”‚
    â†“                                           â”‚
[Decoder]                                       â”‚
  ResBlock + FiLM + Skip â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  ResBlock + FiLM + Skip â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
[Output Conv] â†’ (B, 256, 7, 7)
```

### FiLM æ¡ä»¶æ³¨å…¥

```python
# Feature-wise Linear Modulation
cond = time_emb + text_emb  # åˆå¹¶æ¡ä»¶
scale, shift = MLP(cond).chunk(2)
h = h * (1 + scale) + shift  # åœ¨æ¯ä¸ªResBlockæ³¨å…¥
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### Text â†’ Image (Latent Diffusion)
- âœ… å›¾åƒæ›´è¿è´¯ï¼ˆspatial structureï¼‰
- âœ… é¢œè‰²ã€å½¢çŠ¶æ›´å‡†ç¡®
- âœ… Textæ¡ä»¶çœŸæ­£èµ·ä½œç”¨
- â±ï¸ 50æ­¥çº¦2-5ç§’ï¼ˆGPUï¼‰

### Image â†’ Text (Autoregressive)
- âœ… å¥å­æ›´æµç•…
- âœ… æè¿°æ›´å‡†ç¡®
- â±ï¸ å®æ—¶ç”Ÿæˆï¼ˆ<1ç§’ï¼‰

---

## ğŸ¤” FAQ

**Q: ä¸ºä»€ä¹ˆä¸åœ¨åƒç´ ç©ºé—´åšæ‰©æ•£ï¼Ÿ**
A: å¤ªæ…¢ï¼224Ã—224éœ€è¦50Kä¸ªå€¼ï¼Œ7Ã—7åªéœ€12Kä¸ªå€¼ã€‚Latentç©ºé—´å¿«100å€ã€‚

**Q: Imageâ†’Textä¸ºä»€ä¹ˆä¸ç”¨æ‰©æ•£ï¼Ÿ**
A: æ–‡æœ¬æ˜¯ç¦»æ•£åºåˆ—ï¼ŒTransformerçš„autoregressiveç”Ÿæˆå·²ç»å¾ˆå¥½äº†ã€‚æ‰©æ•£æ˜¯ä¸ºè¿ç»­æ•°æ®è®¾è®¡çš„ã€‚

**Q: æ—§checkpointè¿˜èƒ½ç”¨å—ï¼Ÿ**
A: ä¸èƒ½ã€‚æ¨¡å‹ç»“æ„å˜äº†ï¼Œéœ€è¦é‡æ–°è®­ç»ƒã€‚ä½†è®­ç»ƒä»£ç æ— éœ€ä¿®æ”¹ï¼

**Q: å¦‚ä½•è°ƒè¯•ç”Ÿæˆè´¨é‡ï¼Ÿ**
A:
1. æ£€æŸ¥training lossæ˜¯å¦ä¸‹é™
2. å¢åŠ num_inference_stepsï¼ˆ50â†’100ï¼‰
3. è°ƒæ•´diffusion_weightï¼ˆconfigä¸­ï¼‰
4. ç¡®ä¿contrastive lossæ”¶æ•›ï¼ˆembeddingå¯¹é½å¾ˆé‡è¦ï¼‰

**Q: å¯ä»¥åªç”¨ç›´æ¥è§£ç å—ï¼ˆä¸ç”¨æ‰©æ•£ï¼‰ï¼Ÿ**
A: å¯ä»¥ï¼Œè®¾ç½®`use_diffusion=False`ã€‚ä½†è´¨é‡ä¼šæ˜æ˜¾ä¸‹é™ï¼Œå› ä¸ºæ²¡æœ‰è¿­ä»£refinementã€‚

---

## ğŸ“š å‚è€ƒ

æœ¬å®ç°å‚è€ƒäº†ä»¥ä¸‹å·¥ä½œï¼š
- **Stable Diffusion**: Latentç©ºé—´æ‰©æ•£
- **DALL-E 2**: Textæ¡ä»¶å›¾åƒç”Ÿæˆ
- **DDIM**: å¿«é€Ÿé‡‡æ ·ç®—æ³•
- **FiLM**: æ¡ä»¶æ³¨å…¥æ–¹æ³•

---

## âœ… ä¸‹ä¸€æ­¥

1. âœ… æ¶æ„å®ç°å®Œæˆ
2. ğŸ”„ **è¿è¡Œè®­ç»ƒ**ï¼š`python main.py`
3. ğŸ”„ **æµ‹è¯•ç”Ÿæˆ**ï¼š`python test.py` å’Œ `python test02.py`
4. ğŸ“Š è§‚å¯Ÿæ•ˆæœå¹¶è°ƒä¼˜å‚æ•°

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸ‰
