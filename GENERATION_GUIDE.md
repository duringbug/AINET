# å›¾ç”Ÿæ–‡ & æ–‡ç”Ÿå›¾ ä½¿ç”¨æŒ‡å—

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•è®­ç»ƒå’Œä½¿ç”¨å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹å®ç°**å›¾ç”Ÿæ–‡(Image-to-Text)**å’Œ**æ–‡ç”Ÿå›¾(Text-to-Image)**åŠŸèƒ½ã€‚

---

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹,æ”¯æŒ:

1. **å›¾ç”Ÿæ–‡ (Image-to-Text)**: è¾“å…¥å›¾åƒ â†’ ç”Ÿæˆæè¿°æ–‡æœ¬
2. **æ–‡ç”Ÿå›¾ (Text-to-Image)**: è¾“å…¥æ–‡æœ¬ â†’ ç”Ÿæˆå›¾åƒ

æ¨¡å‹æ¶æ„:
- **ç¼–ç å™¨**: å›¾åƒç¼–ç å™¨(SimpleCNN) + æ–‡æœ¬ç¼–ç å™¨(BERT)
- **è§£ç å™¨**: å›¾åƒè§£ç å™¨(Transposed CNN) + æ–‡æœ¬è§£ç å™¨(Transformer)
- **ç”Ÿæˆæ¨¡å—**: Latent Diffusion UNet (ç”¨äºé«˜è´¨é‡æ–‡ç”Ÿå›¾)

---

## ğŸ“‹ å…³é”®ä¿®æ”¹è¯´æ˜

### âŒ ä¹‹å‰çš„é—®é¢˜
```python
'freeze_bert': True,  # BERTè¢«å†»ç»“,æ— æ³•å­¦ä¹ 
'learning_rate': 1e-3,  # å­¦ä¹ ç‡è¿‡é«˜
'diffusion_weight': 0.3,  # æ‰©æ•£lossæƒé‡è¿‡å¤§
```
**å¯¼è‡´**: Losså¡åœ¨12å·¦å³,å‡†ç¡®ç‡åªæœ‰12.5%

### âœ… ä¿®å¤åçš„é…ç½®
```python
'freeze_bert': False,       # è§£å†»BERT,å…è®¸å­¦ä¹ 
'learning_rate': 2e-4,      # é™ä½å­¦ä¹ ç‡,é€‚åˆBERTå¾®è°ƒ
'warmup_epochs': 2,         # æ·»åŠ warmup
'contrastive_weight': 1.0,  # å¯¹æ¯”å­¦ä¹ æƒé‡
'recon_weight': 0.5,        # é‡å»ºæƒé‡
'diffusion_weight': 0.1,    # é™ä½æ‰©æ•£æƒé‡
```
**é¢„æœŸæ•ˆæœ**:
- Epoch 1-3: å‡†ç¡®ç‡å¿«é€Ÿä¸Šå‡åˆ° 30-50%
- Epoch 5-10: å‡†ç¡®ç‡è¾¾åˆ° 70-90%
- Epoch 10-15: å‡†ç¡®ç‡æ¥è¿‘ 100%

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è®­ç»ƒæ¨¡å‹

```bash
# ç¡®ä¿æ•°æ®é›†å·²ä¸‹è½½
ls data/coco/coco2017/

# å¼€å§‹è®­ç»ƒ(ä½¿ç”¨ä¿®æ”¹åçš„é…ç½®)
python main.py
```

**è®­ç»ƒç›‘æ§æŒ‡æ ‡**:
- `contrastive_loss`: åº”è¯¥ä» ~6 é™åˆ° ~2
- `i2t` (Imageâ†’Textå‡†ç¡®ç‡): åº”è¯¥å¿«é€Ÿä¸Šå‡
- `t2i` (Textâ†’Imageå‡†ç¡®ç‡): åº”è¯¥å¿«é€Ÿä¸Šå‡
- **å¦‚æœå‡†ç¡®ç‡å¡åœ¨12%å·¦å³,è¯´æ˜BERTè¢«å†»ç»“äº†!**

**é¢„æœŸè®­ç»ƒæ—¶é—´** (NVIDIA GPU):
- æ¯ä¸ªepoch: ~30-40åˆ†é’Ÿ (COCO 532Kæ ·æœ¬)
- æ€»è®­ç»ƒæ—¶é—´: ~8-10å°æ—¶ (15 epochs)

### 2. æµ‹è¯•ç”Ÿæˆæ•ˆæœ

è®­ç»ƒå®Œæˆå,è¿è¡Œå¿«é€Ÿæµ‹è¯•:

```bash
# è‡ªåŠ¨æµ‹è¯•å›¾ç”Ÿæ–‡å’Œæ–‡ç”Ÿå›¾
python test_generation.py
```

è¿™ä¼š:
1. è‡ªåŠ¨æ‰¾åˆ°æœ€æ–°çš„checkpoint
2. ç”Ÿæˆ5å¼ æ–‡ç”Ÿå›¾æµ‹è¯•å›¾ç‰‡
3. å¯¹éªŒè¯é›†ä¸­çš„å›¾ç‰‡ç”Ÿæˆæè¿°

### 3. æ‰‹åŠ¨æ¨ç†

#### æ–‡ç”Ÿå›¾ (Text-to-Image)

```bash
python inference.py \
    --checkpoint outputs/best_model \
    --mode t2i \
    --text "a dog playing in the park" \
    --output generated_dog.png \
    --steps 50
```

**å‚æ•°è¯´æ˜**:
- `--steps`: æ‰©æ•£æ­¥æ•°
  - 10-20 steps: å¿«é€Ÿç”Ÿæˆ,è´¨é‡ä¸€èˆ¬
  - 30-50 steps: æ¨è,è´¨é‡å¥½
  - 50-100 steps: æœ€ä½³è´¨é‡,ä½†å¾ˆæ…¢

#### å›¾ç”Ÿæ–‡ (Image-to-Text)

```bash
python inference.py \
    --checkpoint outputs/best_model \
    --mode i2t \
    --image path/to/your/image.jpg
```

#### åŒæ—¶æµ‹è¯•ä¸¤ä¸ªåŠŸèƒ½

```bash
python inference.py \
    --checkpoint outputs/best_model \
    --mode both \
    --image path/to/image.jpg \
    --text "a beautiful landscape" \
    --output generated.png
```

---

## ğŸ“Š è®­ç»ƒæ•ˆæœé¢„æœŸ

### é˜¶æ®µ1: Epoch 1-2 (Warmup)
```
Loss: 8-10
i2tå‡†ç¡®ç‡: 20-30%
t2iå‡†ç¡®ç‡: 20-30%
```

### é˜¶æ®µ2: Epoch 3-7 (å¿«é€Ÿå­¦ä¹ )
```
Loss: 4-6
i2tå‡†ç¡®ç‡: 50-70%
t2iå‡†ç¡®ç‡: 50-70%
```

### é˜¶æ®µ3: Epoch 8-15 (æ”¶æ•›)
```
Loss: 2-3
i2tå‡†ç¡®ç‡: 85-100%
t2iå‡†ç¡®ç‡: 85-100%
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜1: Lossä¸ä¸‹é™,å¡åœ¨12å·¦å³

**åŸå› **: BERTè¢«å†»ç»“äº†

**è§£å†³**:
```python
# æ£€æŸ¥ main.py ç¬¬1640è¡Œ
'freeze_bert': False,  # å¿…é¡»æ˜¯False!
```

### é—®é¢˜2: Lossä¸‹é™å¾ˆæ…¢

**å¯èƒ½åŸå› **:
1. å­¦ä¹ ç‡å¤ªé«˜
2. Diffusion lossä¸»å¯¼æ€»loss

**è§£å†³**:
```python
'learning_rate': 1e-4,  # é™ä½å­¦ä¹ ç‡
'diffusion_weight': 0.05,  # è¿›ä¸€æ­¥é™ä½æ‰©æ•£æƒé‡
```

### é—®é¢˜3: å†…å­˜ä¸è¶³ (OOM)

**è§£å†³**:
```python
'batch_size': 32,  # ä»64é™åˆ°32
'num_workers': 4,  # ä»8é™åˆ°4
```

### é—®é¢˜4: ç”Ÿæˆçš„å›¾åƒè´¨é‡å·®

**å¯èƒ½åŸå› **:
1. è®­ç»ƒè¿˜æœªæ”¶æ•›
2. æ‰©æ•£æ­¥æ•°å¤ªå°‘

**è§£å†³**:
1. å¤šè®­ç»ƒå‡ ä¸ªepoch
2. æ¨ç†æ—¶ä½¿ç”¨æ›´å¤šsteps: `--steps 100`

---

## ğŸ’¡ é«˜çº§ç”¨æ³•

### Python APIä½¿ç”¨

```python
from inference import ImageTextGenerator

# åˆå§‹åŒ–
generator = ImageTextGenerator('outputs/best_model', device='cuda')

# æ–‡ç”Ÿå›¾
image = generator.text_to_image(
    "a beautiful sunset over mountains",
    num_inference_steps=50,
    save_path='sunset.png'
)

# å›¾ç”Ÿæ–‡
caption = generator.image_to_text('path/to/image.jpg')
print(f"Caption: {caption}")

# æ‰¹é‡ç”Ÿæˆ
texts = ["a cat", "a dog", "a bird"]
images = generator.batch_text_to_image(texts, save_dir='batch_output')
```

### æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡å›¾ç”Ÿæ–‡
image_paths = ['img1.jpg', 'img2.jpg', 'img3.jpg']
captions = generator.batch_image_to_text(image_paths)

for img_path, caption in zip(image_paths, captions):
    print(f"{img_path}: {caption}")
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### åŠ é€Ÿè®­ç»ƒ
1. ä½¿ç”¨æ›´å¤§çš„batch size (å¦‚æœGPUå†…å­˜è¶³å¤Ÿ)
2. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (æ·»åŠ  `torch.cuda.amp`)
3. å‡å°‘diffusionæ­¥æ•°åˆ°500

### æå‡ç”Ÿæˆè´¨é‡
1. è®­ç»ƒæ›´å¤šepoch (20-30)
2. ä½¿ç”¨ResNet50æ›¿ä»£SimpleCNN:
   ```python
   'use_simple_cnn': False,
   ```
3. å¢åŠ embeddingç»´åº¦:
   ```python
   'embed_dim': 768,
   ```

---

## ğŸ¨ ç¤ºä¾‹è¾“å‡º

### æ–‡ç”Ÿå›¾ç¤ºä¾‹

**è¾“å…¥æ–‡æœ¬**: "a dog playing in the park"

**ç”Ÿæˆå›¾åƒ**: åº”è¯¥ç”Ÿæˆä¸€å¼ ç‹—åœ¨å…¬å›­ç©è€çš„å›¾ç‰‡

### å›¾ç”Ÿæ–‡ç¤ºä¾‹

**è¾“å…¥å›¾åƒ**: COCOéªŒè¯é›†å›¾ç‰‡

**ç”Ÿæˆæè¿°**: "a person riding a bicycle on the street"

---

## ğŸ“ æ¨¡å‹æ¶æ„è¯´æ˜

```
è¾“å…¥å›¾åƒ â†’ Image Encoder â†’ Image Embedding (512-dim)
                                 â†“
                          [ç»Ÿä¸€å‘é‡ç©ºé—´]
                                 â†“
è¾“å…¥æ–‡æœ¬ â†’ Text Encoder (BERT) â†’ Text Embedding (512-dim)

ç”Ÿæˆè·¯å¾„:
- å›¾ç”Ÿæ–‡: Image Embedding â†’ Text Decoder â†’ æ–‡æœ¬
- æ–‡ç”Ÿå›¾: Text Embedding â†’ Latent Diffusion â†’ Image Decoder â†’ å›¾åƒ
```

**å…³é”®ç»„ä»¶**:
1. **Contrastive Learning**: å¯¹é½å›¾åƒå’Œæ–‡æœ¬embedding
2. **Reconstruction**: è®­ç»ƒdecoderé‡å»ºåŸå§‹æ•°æ®
3. **Latent Diffusion**: é«˜è´¨é‡å›¾åƒç”Ÿæˆ

---

## ğŸ” è°ƒè¯•æŠ€å·§

### æŸ¥çœ‹å„ä¸ªlossçš„å€¼

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­,è§‚å¯Ÿè¿›åº¦æ¡æ˜¾ç¤º:
```
loss=5.23, cont=2.1, rec=2.8, diff=0.3
```

- `cont` (contrastive): å¯¹æ¯”å­¦ä¹ loss,åº”è¯¥é™åˆ°1-3
- `rec` (reconstruction): é‡å»ºloss,åº”è¯¥é™åˆ°2-5
- `diff` (diffusion): æ‰©æ•£loss,åº”è¯¥é™åˆ°0.1-0.5

### æ£€æŸ¥å‡†ç¡®ç‡

```
i2t=45.2%, t2i=43.8%
```

- åˆæœŸåº”è¯¥å¿«é€Ÿä¸Šå‡
- æœ€ç»ˆåº”è¯¥æ¥è¿‘100%

---

## ğŸ¯ æœ€ç»ˆç›®æ ‡

è®­ç»ƒæˆåŠŸçš„æ ‡å¿—:
- âœ… Validation loss < 3.0
- âœ… i2tå‡†ç¡®ç‡ > 90%
- âœ… t2iå‡†ç¡®ç‡ > 90%
- âœ… ç”Ÿæˆçš„æ–‡æœ¬æè¿°å‡†ç¡®
- âœ… ç”Ÿæˆçš„å›¾åƒä¸æ–‡æœ¬ç›¸å…³

å¦‚æœè¾¾åˆ°ä»¥ä¸Šæ ‡å‡†,æ­å–œ!ä½ çš„æ¨¡å‹å·²ç»å¯ä»¥ç”¨äºå®é™…çš„å›¾ç”Ÿæ–‡å’Œæ–‡ç”Ÿå›¾ä»»åŠ¡äº†!
